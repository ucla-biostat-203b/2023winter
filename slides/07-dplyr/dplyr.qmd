---
title: "Data Transformation With dplyr"
subtitle: Biostat 203B
author: "Dr. Hua Zhou @ UCLA"
date: "`r format(Sys.time(), '%d %B, %Y')`"
format:
  html:
    theme: cosmo
    number-sections: true
    toc: true
    toc-depth: 4
    toc-location: left
    code-fold: false
bibliography: "../bib-HZ.bib"
csl: "../apa.csl"
knitr:
  opts_chunk: 
    fig.align: 'center'
    fig.width: 6
    fig.height: 4
    message: FALSE
    cache: false
---

Display machine information for reproducibility.

::: {.panel-tabset}

#### R

```{r}
sessionInfo()
```

#### Python

```{python}
import IPython
print(IPython.sys_info())
```

#### Julia

```{julia}
using InteractiveUtils
versioninfo()
```

:::

Load tidyverse (R), Pandas (Python), and DataFrames.jl (Julia).

::: {.panel-tabset}

#### R

```{r}
library(tidyverse)
```

#### Python

```{python}
# Load the pandas library
import pandas as pd
# Load numpy for array manipulation
import numpy as np
```

#### Julia

```{julia}
using DataFrames, Pipe, StatsBase
```

:::

A typical data science project:

<p align="center">
<img src="./data-science.png" height="275">
</p>

## nycflights13 data

- Available from the nycflights13 package. 

- 336,776 flights that departed from New York City in 2013:

::: {.panel-tabset}

#### R

```{r}
library("nycflights13")
flights
```

#### Python

The nycflights13 data is available from the nycflights13 package in Python.
```{python}
from nycflights13 import flights

flights
```

Note there are some differences of this `flights` data from that in tidyverse. The data types for some variables are different. There are no natural ways in Pandas to hold integer column with missing values; so `dep_time` , `arr_time` are `float64` instead of `int64`. The `time_hour` data seems to be very different from tidyverse.
```{python}
flights.info()
```

To be more consistent with `nycflights13` in tidyverse, we cast `time_hour` to `datetime` type.
```{python}
flights['time_hour'] = pd.to_datetime(flights['time_hour'])
```

#### Julia

Let's use RCall.jl to retrieve the nycflights13 data from R.
```{julia}
using RCall

R"""
library(nycflights13)
"""

flights = rcopy(R"flights")
```

:::

To display more rows or columns: 

::: {.panel-tabset}

#### R

- By default, tibble prints the first 10 rows and all columns _that fit on screen_.
```{r}
flights
```

- To change number of rows and columns to display:
```{r}
nycflights13::flights %>% 
  print(n = 10, width = Inf)
```
Here we see the **pipe operator** `%>%` pipes the output from previous command to the (first) argument of the next command.

- To change the default print setting globally:
    - `options(tibble.print_max = n, tibble.print_min = m)`: if more than `m` rows, print only `n` rows.
    - `options(dplyr.print_min = Inf)`: print all row.
    - `options(tibble.width = Inf)`: print all columns.

#### Python

Pandas by default displays 10 rows and limits the number of columns to the display area.
```{python}
from nycflights13 import flights
flights
```
We can override this behavior by
```{python}
#| eval: false
pd.set_option("display.max_rows", 500)
pd.set_option("display.max_columns", 20)
```


#### Julia

By default DataFrames.jl limits the number of rows and columns when displaying a data frame in a Jupyter Notebook to 25 and 100, respectively. You can override this behavior by changing the values of the `ENV["DATAFRAMES_COLUMNS"]` and `ENV["DATAFRAMES_ROWS"]` variables to hold the maximum number of columns and rows of the output. All columns or rows will be printed if those numbers are equal or lower than 0.

:::

## dplyr basics

* Pick observations (rows) by their values: `filter()`.

* Reorder the rows: `arrange()`.

* Pick variables (columns) by their names: `select()`.

* Create new variables with functions of existing variables: `mutate()`.

* Collapse many values down to a single summary: `summarise()`.

```
verb          meaning
--------------------------------------------
filter()      subset observations (or rows)
arrange()     re-order the observations
distinct()    remove duplicate entries
select()      select variables (or columns)
mutate()      add new variables (or columns)
group_by()    aggregate
summarise()   reduce to a single row
left_join()   merge two data objects
collect()     force computation and bring data back into R
```

## Manipulate rows (cases)

### Filter rows with `filter()`

- Flights on Jan 1st:

::: {.panel-tabset}

#### R

```{r}
# same as filter(flights, month == 1 & day == 1)
filter(flights, month == 1, day == 1)
```

#### Python

```{python}
flights[(flights['month'] == 1) & (flights['day'] == 1)]
```

#### Julia

```{julia}
filter(row -> (row.month == 1) & (row.day == 1), flights)
```

:::


- Flights in Nov or Dec:

::: {.panel-tabset}

#### R

```{r}
filter(flights, month == 11 | month == 12)
```

#### Python

```{python}
flights[(flights['month'] == 11) | (flights['month'] == 12)]
```

#### Julia

```{julia}
filter(row -> (row.month == 11) | (row.month == 12), flights)
```
:::

### Remove rows with duplicate values

- One row from each month:

::: {.panel-tabset}

#### R

```{r}
distinct(flights, month, .keep_all = TRUE)
```

- With `.keep_all = FALSE`, only distinct values of the variable are selected:
```{r}
distinct(flights, month)
```

#### Python

```{python}
flights.drop_duplicates(subset = ['month'])
```

#### Julia

```{julia}
unique(flights, :month)
```

:::

### Sample rows

::: {.panel-tabset}

#### R

- Randomly select `n` rows:
```{r}
sample_n(flights, 10, replace = TRUE)
```

- Randomly select fraction of rows:
```{r}
sample_frac(flights, 0.1, replace = TRUE)
```

#### Python

Sample `n=10` rows.
```{python}
flights.sample(n = 10, axis = 0)
```

Sample 10\% rows:
```{python}
flights.sample(frac = 0.1)
```

#### Julia

I'm not sure whether there's a native function in DataFrames.jl for sampling.

Sample 5 rows:
```{julia}
rowidx = StatsBase.sample(1:nrow(flights), 5, replace = false);
flights[rowidx, :]
```
Sample 10\% rows:
```{julia}
rowidx = StatsBase.sample(
  1:nrow(flights), 
  round(Int, nrow(flights) * 0.1), 
  replace = false);
flights[rowidx, :]
```

:::


### Select rows by position

::: {.panel-tabset}

#### R

- Select rows by position:
```{r}
slice(flights, 1:5)
```

- First rows:
```{r}
slice_head(flights, n = 5)
```

- Last rows:
```{r}
slice_tail(flights, n = 5)
```

- Top `n` rows with the highest values:
```{r}
# deprecated: top_n(flights, 5, wt = time_hour)
# This function is quick
slice_max(flights, n = 5, order_by = time_hour)
```

- Bottom `n` rows with lowest values:
```{r}
# deprecated: top_n(flights, -5, wt = time_hour)
# Why it takes REALLY long???
slice_max(flights, n = 5, order_by = desc(time_hour)) # is fast
# slice_min(flights, n = 5, order_by = time_hour) # very slow
```

- `slice_*` verbs apply to groups for grouped tibbles.

#### Python

- Select rows by position:
```{python}
flights.iloc[range(0, 5)]
```

- First rows:
```{python}
flights.head(5)
```

- Last rows:
```{python}
flights.tail(5)
```

- Top `n` rows with the highest values:
```{python}
flights.nlargest(n = 5, columns = 'time_hour')
```

- Bottom `n` rows with lowest values:
```{python}
flights.nsmallest(n = 5, columns = 'time_hour')
```
I don't think `nlargest` and `nsmallest` apply to grouped DataFrame. But I may be wrong.

#### Julia

- Select rows by position:
```{julia}
flights[1:5, :]
```

- First rows:
```{julia}
first(flights, 5)
```

- Last rows:
```{julia}
last(flights, 5)
```

- Top `n` rows with the highest values:
```{julia}
last(sort(flights, [:time_hour]), 5)
```

- Bottom `n` rows with lowest values:
```{julia}
first(sort(flights, [:time_hour]), 5)
```

:::

### Arrange rows with `arrange()`

- Sort in ascending order:
```{r}
arrange(flights, year, month, day)
```

----

- Sort in descending order:
```{r}
arrange(flights, desc(arr_delay)) %>%
  print(width = Inf)
```

----

- By default, `arrange` ignores grouping in grouped tibbles. Set `.by_group = TRUE` to arrange within each group.

## Manipulate columns (variables)

### Select columns with `select()`

- Select columns by variable names:
```{r}
select(flights, year, month, day)
```

- Pull values of _one_ column as a vector:
```{r}
#| eval: false
pull(flights, year)
```

----

- Select columns between two variables:
```{r}
select(flights, year:day)
```

----

- Select columns _except_ those between two variables:
```{r}
select(flights, -(year:day))
```

----

- Select columns by positions:
```{r}
select(flights, seq(1, 10, by = 2))
```

----

- Move variables to the start of data frame:
```{r}
select(flights, time_hour, air_time, everything())
```

----
 
- Helper functions.

    * `starts_with("abc")`: matches names that begin with “abc”.

    * `ends_with("xyz")`: matches names that end with “xyz”.

    * `contains("ijk")`: matches names that contain “ijk”.

    * `matches("(.)\\1")`: selects variables that match a regular expression.

    * `num_range("x", 1:3)`: matches x1, x2 and x3.
    
    * `one_of()`

### Add new variables with `mutate()`

- Add variables `gain` and `speed`:
```{r}
flights_sml <- 
  select(flights, year:day, ends_with("delay"), distance, air_time)
flights_sml
```
```{r}
mutate(flights_sml,
       gain = arr_delay - dep_delay,
       speed = distance / air_time * 60
)
```

----

- Refer to columns that you’ve just created:
```{r}
mutate(flights_sml,
       gain = arr_delay - dep_delay,
       hours = air_time / 60,
       gain_per_hour = gain / hours
)
```

----

- Only keep the new variables by `transmute()`:
```{r}
transmute(flights,
          gain = arr_delay - dep_delay,
          hours = air_time / 60,
          gain_per_hour = gain / hours
)
```

----

- `mutate_all()`: apply funs to all columns.
```{r}
#| eval: false
mutate_all(data, funs(log(.), log2(.)))
```

- `mutate_at()`: apply funs to specific columns.
```{r}
#| eval: false
mutate_at(data, vars(-Species), funs(log(.)))
```

- `mutate_if()`: apply funs of one type
```{r}
#| eval: false
mutate_if(data, is.numeric, funs(log(.)))
```

## Summaries

### Summaries with `summarise()`

- Mean of a variable:
```{r}
summarise(flights, delay = mean(dep_delay, na.rm = TRUE))
```

----
 
- Convert a tibble into a grouped tibble:
```{r}
(by_day <- group_by(flights, year, month, day))
```

----

- Grouped summaries:
```{r}
summarise(by_day, delay = mean(dep_delay, na.rm = TRUE))
```

### Pipe

- Consider following analysis (find destinations excluding `HNL` that have >20 flights, and calculate the average distances and arrival delay):
```{r}
#| message: false
by_dest <- group_by(flights, dest)
delay <- summarise(by_dest, count = n(),
                   dist = mean(distance, na.rm = TRUE),
                   delay = mean(arr_delay, na.rm = TRUE)
)
delay <- filter(delay, count > 20, dest != "HNL")
delay
```

----

- Cleaner code using pipe `%>%`:
```{r}
delays <- flights %>% 
  group_by(dest) %>% 
  summarise(
    count = n(),
    dist = mean(distance, na.rm = TRUE),
    delay = mean(arr_delay, na.rm = TRUE)
  ) %>% 
  filter(count > 20, dest != "HNL")
delays
```
    
----

- ggplot2 accepts pipe too.
```{r}
delays %>%
  ggplot(mapping = aes(x = dist, y = delay)) +
  geom_point(aes(size = count), alpha = 1/3) + 
  geom_smooth(se = FALSE) + 
  labs(x = "Distance from NYC (miles)",
       y = "Arrival delay (mins)")
```

### Other summary functions

- Location: `mean(x)`, `median(x)`.
```{r}
not_cancelled <- flights %>% 
  filter(!is.na(dep_delay), !is.na(arr_delay))
not_cancelled
```
```{r}
not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(
    avg_delay1 = mean(arr_delay),
    avg_delay2 = mean(arr_delay[arr_delay > 0]) # the average positive delay
  )
```
    
----

- Spread: `sd(x)`, `IQR(x)`, `mad(x)`.
```{r}
# destinations with largest variation in distance
not_cancelled %>% 
  group_by(dest) %>% 
  summarise(distance_sd = sd(distance)) %>% 
  arrange(desc(distance_sd))
```

----
    
- Rank: `min(x)`, `quantile(x, 0.25)`, `max(x)`.
```{r}
# Earliest and latest flights on each day?
not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(
    first = min(dep_time),
    last = max(dep_time)
  )
```

----

- Position: `first(x)`, `nth(x, 2)`, `last(x)`.
```{r}
not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(
    first_dep = first(dep_time), 
    last_dep = last(dep_time)
  )
```

----

- Count: `n(x)`, `sum(!is.na(x))`, `n_distinct(x)`.
```{r}
# Which destinations have the most carriers?
not_cancelled %>% 
  group_by(dest) %>% 
  summarise(carriers = n_distinct(carrier)) %>% 
  arrange(desc(carriers))
```

----

- 
```{r}
# which destination has most flights from NYC?
not_cancelled %>% 
  count(dest) %>%
  arrange(desc(n))
```

---- 

- 
```{r}
# which aircraft flew most in 2013?
not_cancelled %>% 
  count(tailnum, wt = distance) %>%
  arrange(desc(n))
```

----

-
```{r}
# How many flights left before 5am? (these usually indicate delayed
# flights from the previous day)
not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(n_early = sum(dep_time < 500)) %>%
  arrange(desc(n_early))
```

----

-
```{r}
# What proportion of flights are delayed by more than an hour?
not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(hour_perc = mean(arr_delay > 60)) %>%
  arrange(desc(hour_perc))
```

## Grouped mutates (and filters)

- Recall the `flights_sml` tibble created earlier:
```{r}
flights_sml
```

- Find the worst members of each group:
```{r}
flights_sml %>% 
  group_by(year, month, day) %>%
  filter(rank(desc(arr_delay)) < 10)
```

----

- Find all groups bigger than a threshold:
```{r}
(popular_dests <- flights %>% 
   group_by(dest) %>% 
   filter(n() > 365))
```

----

- Standardise to compute per group metrics:
```{r}
popular_dests %>% 
  filter(arr_delay > 0) %>%
  mutate(prop_delay = arr_delay / sum(arr_delay)) %>%
  select(year:day, dest, arr_delay, prop_delay) %>%
  print(width = Inf)
```

## Combine tables

nycflights13 package has >1 tables:

- We already know a lot about flights:
```{r}
flights %>% print(width = Inf)
```

----

- airlines:
```{r}
airlines
```

----

- airports:
```{r}
airports
```

----

- planes:
```{r}
planes
```

----

- Weather:
```{r}
weather %>%
  print(width = Inf)
```

## Relational data

<p align="center">
<img src="./relational-nycflights.png" height="375">
</p>

For the MIMIC-III data, the relation structure can be explored at <https://mit-lcp.github.io/mimic-schema-spy/relationships.html>.

### Keys

- A **primary key** uniquely identifies an observation in its own table.

- A **foreign key** uniquely identifies an observation in another table.

## Combine variables (columns)

### Demo tables

-
```{r}
(x <- tribble(
  ~key, ~val_x,
  1, "x1",
  2, "x2",
  3, "x3"
))
```
```{r}
(y <- tribble(
  ~key, ~val_y,
  1, "y1",
  2, "y2",
  4, "y3"
))
```

### Inner join

- An **inner join** matches pairs of observations whenever their keys are equal:

<p align="center">
<img src="./join-inner.png" height="150">
</p>

- 
```{r}
inner_join(x, y, by = "key")
```
Same as
```{r}
#| eval: false
x %>% inner_join(y, by = "key")
```

### Outer join

- An **outer join** keeps observations that appear in at least one of the tables. 

- Three types of outer joins:

    - A **left join** keeps all observations in `x`.
```{r}
left_join(x, y, by = "key")
```
    
    - A **right join** keeps all observations in `y`.
```{r}
right_join(x, y, by = "key")
```
    
    - A **full join** keeps all observations in `x` or `y`.
```{r}
full_join(x, y, by = "key")
```
    
    <p align="center">
    <img src="./join-outer.png" height="275">
    </p>
    
### Duplicate keys

- One table has duplicate keys.

    <p align="center">
    <img src="./join-one-to-many.png" height="200">
    </p>
    
----    

- 
```{r}
x <- tribble(
  ~key, ~val_x,
  1, "x1",
  2, "x2",
  2, "x3",
  1, "x4"
)
y <- tribble(
  ~key, ~val_y,
  1, "y1",
  2, "y2"
)
left_join(x, y, by = "key")
```

----

- Both tables have duplicate keys. You get all possible combinations, the Cartesian product:

    <p align="center">
    <img src="./join-many-to-many.png" height="250">
    </p>

----

- 
```{r}
x <- tribble(
  ~key, ~val_x,
  1, "x1",
  2, "x2",
  2, "x3",
  3, "x4"
)
y <- tribble(
  ~key, ~val_y,
  1, "y1",
  2, "y2",
  2, "y3",
  3, "y4"
)
left_join(x, y, by = "key")
```

----

- Let's create a narrower table from the flights data:
```{r}
flights2 <- flights %>% 
  select(year:day, hour, origin, dest, tailnum, carrier)
flights2
```

- We want to merge with the `weather` table:
```{r}
weather
```

### Defining the key columns

- `by = NULL` (default): use all variables that appear in both tables:
```{r}
# same as: flights2 %>% left_join(weather)
left_join(flights2, weather)
```

----

- `by = "x"`: use the common variable `x`:
```{r}
# same as: flights2 %>% left_join(weather)
left_join(flights2, planes, by = "tailnum")
```

----

- `by = c("a" = "b")`: match variable `a` in table `x` to the variable `b` in table `y`.
```{r}
# same as: flights2 %>% left_join(weather)
left_join(flights2, airports, by = c("dest" = "faa"))
```

## Combine cases (rows)

----

- Top 10 most popular destinations:
```{r}
top_dest <- flights %>%
  count(dest, sort = TRUE) %>%
  head(10)
top_dest
```

- How to filter the cases that fly to these destinations?     
    
### Semi-join

- `semi_join(x, y)` keesp the rows in `x` that have a match in `y`.

    <p align="center">
    <img src="./join-semi.png" height="200">
    </p>

----

```{r}
semi_join(flights, top_dest)
```

### Anti-join

- `anti_join(x, y)` keeps the rows that don’t have a match.

    <p align="center">
    <img src="./join-anti.png" height="200">
    </p>

- Useful to see what will not be joined.

----

-
```{r}
flights %>% 
  anti_join(planes, by = "tailnum") %>%
  count(tailnum, sort = TRUE)
```

## Set operations

- Generate two tables:
```{r}
(df1 <- tribble(
  ~x, ~y,
  1,  1,
  2,  1
))
```
```{r}
(df2 <- tribble(
  ~x, ~y,
  1,  1,
  1,  2
))
```

----

- `bind_rows(x, y)` stacks table `x` one on top of `y`. 
```{r}
bind_rows(df1, df2)
```

- `intersect(x, y)` returns rows that appear in both `x` and `y`.
```{r}
intersect(df1, df2)
```

----

- `union(x, y)` returns unique observations in `x` and `y`.
```{r}
union(df1, df2)
```

----

- `setdiff(x, y)` returns rows that appear in `x` but not in `y`.
```{r}
setdiff(df1, df2)
```
```{r}
setdiff(df2, df1)
```

## Cheat sheet  

[RStudio cheat sheet](https://raw.githubusercontent.com/rstudio/cheatsheets/master/data-transformation.pdf) is extremely helpful.    
